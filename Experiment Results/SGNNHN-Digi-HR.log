start of program
#############################################################################
Name of test: 
	merge-4
Changes made: 
	1. based on 55.75, change decision function to 1->1->1->num_leaves
	2. change mu_dropout to 0.4
	3. add a conv layer outside the tree
Namespace(batchSize=256, cutnum=10, dataset='diginetica', epoch=30, hiddenSize=256, l2=0.0001, lr=0.001, lr_dc=0.1, lr_dc_step=10, patience=2, step=1, tau=12)
-------------------------------------------------------
epoch:  0
start training:  2023-01-16 15:08:50.575403
[0/2811] Loss: 10.7476
[563/2811] Loss: 7.2825
[1126/2811] Loss: 6.0729
[1689/2811] Loss: 5.2519
[2252/2811] Loss: 5.2714
	Loss:	17747.547
start predicting:  2023-01-16 15:27:22.739734
Best Result:
	Recall@20:	51.7781	MMR@20:	17.5387	Epoch:	0,	0
-------------------------------------------------------
epoch:  1
start training:  2023-01-16 15:28:44.443311
[0/2811] Loss: 6.7875
[563/2811] Loss: 5.0794
[1126/2811] Loss: 5.1444
[1689/2811] Loss: 4.7497
[2252/2811] Loss: 5.0466
	Loss:	14435.328
start predicting:  2023-01-16 17:39:29.854128
Best Result:
	Recall@20:	52.5711	MMR@20:	17.8131	Epoch:	1,	1
-------------------------------------------------------
epoch:  2
start training:  2023-01-16 17:56:38.005045
[0/2811] Loss: 6.3564
[563/2811] Loss: 5.0376
[1126/2811] Loss: 5.1059
[1689/2811] Loss: 4.7508
[2252/2811] Loss: 5.0056
	Loss:	14317.352
start predicting:  2023-01-16 21:00:23.062627
Best Result:
	Recall@20:	52.8002	MMR@20:	17.8755	Epoch:	2,	2
-------------------------------------------------------
epoch:  3
start training:  2023-01-16 21:17:16.082203
[0/2811] Loss: 6.3011
[563/2811] Loss: 5.0151
[1126/2811] Loss: 5.0675
[1689/2811] Loss: 4.7092
[2252/2811] Loss: 4.9694
	Loss:	14236.534
start predicting:  2023-01-17 00:21:02.531949
Best Result:
	Recall@20:	52.9945	MMR@20:	17.9461	Epoch:	3,	3
-------------------------------------------------------
epoch:  4
start training:  2023-01-17 00:37:55.384489
[0/2811] Loss: 6.2289
[563/2811] Loss: 4.9962
[1126/2811] Loss: 5.0386
[1689/2811] Loss: 4.6921
[2252/2811] Loss: 4.9537
	Loss:	14168.927
start predicting:  2023-01-17 03:41:21.347514
Best Result:
	Recall@20:	53.2337	MMR@20:	17.9687	Epoch:	4,	4
-------------------------------------------------------
epoch:  5
start training:  2023-01-17 03:58:31.687975
[0/2811] Loss: 6.1920
[563/2811] Loss: 4.9785
[1126/2811] Loss: 4.9972
[1689/2811] Loss: 4.6656
[2252/2811] Loss: 4.9224
	Loss:	14079.135
start predicting:  2023-01-17 07:02:16.347933
Best Result:
	Recall@20:	53.4077	MMR@20:	17.9695	Epoch:	5,	5
-------------------------------------------------------
epoch:  6
start training:  2023-01-17 07:19:12.808363
[0/2811] Loss: 6.1436
[563/2811] Loss: 4.9454
[1126/2811] Loss: 4.9853
[1689/2811] Loss: 4.6490
[2252/2811] Loss: 4.8947
	Loss:	13995.787
start predicting:  2023-01-17 10:22:45.424419
Best Result:
	Recall@20:	53.5555	MMR@20:	18.0121	Epoch:	6,	6
-------------------------------------------------------
epoch:  7
start training:  2023-01-17 10:39:45.121737
[0/2811] Loss: 6.0937
[563/2811] Loss: 4.9055
[1126/2811] Loss: 4.9572
[1689/2811] Loss: 4.6185
[2252/2811] Loss: 4.8667
	Loss:	13914.634
start predicting:  2023-01-17 13:43:08.568672
Best Result:
	Recall@20:	53.7150	MMR@20:	18.0413	Epoch:	7,	7
-------------------------------------------------------
epoch:  8
start training:  2023-01-17 14:00:00.489026
[0/2811] Loss: 6.0441
[563/2811] Loss: 4.8789
[1126/2811] Loss: 4.9383
[1689/2811] Loss: 4.6033
[2252/2811] Loss: 4.8575
	Loss:	13849.073
start predicting:  2023-01-17 17:03:50.014799
Best Result:
	Recall@20:	53.8194	MMR@20:	18.0759	Epoch:	8,	8
-------------------------------------------------------
epoch:  9
start training:  2023-01-17 17:20:49.892750
[0/2811] Loss: 5.9904
[563/2811] Loss: 4.8545
[1126/2811] Loss: 4.9084
[1689/2811] Loss: 4.5984
[2252/2811] Loss: 4.8342
	Loss:	13793.393
start predicting:  2023-01-17 20:24:27.505268
Best Result:
	Recall@20:	53.8948	MMR@20:	18.1031	Epoch:	9,	9
-------------------------------------------------------
epoch:  10
start training:  2023-01-17 20:41:12.921130
[0/2811] Loss: 5.9580
[563/2811] Loss: 4.6721
[1126/2811] Loss: 4.6044
[1689/2811] Loss: 4.2461
[2252/2811] Loss: 4.2827
	Loss:	12786.330
start predicting:  2023-01-17 23:44:24.491218
Best Result:
	Recall@20:	55.7432	MMR@20:	18.7091	Epoch:	10,	10
-------------------------------------------------------
epoch:  11
start training:  2023-01-18 00:01:49.920705
[0/2811] Loss: 5.6086
[563/2811] Loss: 4.4412
[1126/2811] Loss: 4.4308
[1689/2811] Loss: 4.1225
[2252/2811] Loss: 4.2209
	Loss:	12334.029
start predicting:  2023-01-18 03:05:12.460428
Best Result:
	Recall@20:	55.9085	MMR@20:	18.7792	Epoch:	11,	11
-------------------------------------------------------
epoch:  12
start training:  2023-01-18 03:19:39.563548
[0/2811] Loss: 5.4027
[563/2811] Loss: 4.3438
[1126/2811] Loss: 4.3492
[1689/2811] Loss: 4.0691
[2252/2811] Loss: 4.1902
	Loss:	12144.873
start predicting:  2023-01-18 05:35:40.361976
Best Result:
	Recall@20:	55.9085	MMR@20:	18.7792	Epoch:	11,	11
-------------------------------------------------------
epoch:  13
start training:  2023-01-18 05:48:08.727114
[0/2811] Loss: 5.2645
[563/2811] Loss: 4.2893
[1126/2811] Loss: 4.2980
[1689/2811] Loss: 4.0386
[2252/2811] Loss: 4.1759
	Loss:	12034.520
start predicting:  2023-01-18 08:04:23.209117
Best Result:
	Recall@20:	55.9085	MMR@20:	18.7792	Epoch:	11,	11
-------------------------------------------------------
Run time: 148066.590391 s
